{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Zero-inflated Gaussian Processes in GPFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgpf\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpf' is not defined"
     ]
    }
   ],
   "source": [
    "gpf.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 13:25:56.932251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-07 13:25:56.932311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-07 13:25:56.999153: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-07 13:26:01.350633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-07 13:26:01.351292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-07 13:26:01.351309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-07 13:26:17.018636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-07 13:26:17.018693: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-07 13:26:17.018732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c1cmp063.pax.tufts.edu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import gpflow as gpf\n",
    "import numpy as np\n",
    "gpf.config.set_default_float(np.float32)\n",
    "\n",
    "gpf.config.set_default_jitter(tf.cast(1e-6, dtype=gpf.default_float()))\n",
    "from onoffgpf import OnOffSVGP, OnOffLikelihood, OnOffPoissonLikelihood\n",
    "from onoffgpf.PlotOnOff1D import PlotOnOff1D\n",
    "\n",
    "from gpflow.ci_utils import ci_niter\n",
    "\n",
    "import gpflow\n",
    "\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load simulated dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matdata = sio.loadmat('data/toydata.mat')\n",
    "Xtrain = matdata['x'].astype(gpf.default_float())\n",
    "Ytrain = matdata['y'].astype(gpf.default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain[(Xtrain<=2)] = 1\n",
    "Ytrain[(Xtrain>2) & (Xtrain<3)] = 0\n",
    "Ytrain[(Xtrain>3) & (Xtrain<3.5)] = 3\n",
    "Ytrain[(Xtrain>3.5) & (Xtrain<4)] = 4\n",
    "Ytrain[(Xtrain>=4)] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Xtrain,Ytrain)\n",
    "plt.title(\"Simulated data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train specifications & variable initializations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 8000\n",
    "num_inducing   = 10\n",
    "\n",
    "# initalize kernel parameters\n",
    "kf = gpf.kernels.RBF(variance=1, lengthscales=2)\n",
    "#kf.lengthscales = 2.\n",
    "#kf.variance = 1.\n",
    "\n",
    "kg = gpf.kernels.RBF(variance=5, lengthscales=2)\n",
    "#kg.lengthscales = 2.\n",
    "#kg.variance = 5.\n",
    "\n",
    "# initialise equally spaced inducing point locations\n",
    "Zf = np.delete(np.linspace(min(Xtrain),max(Xtrain),num_inducing,endpoint=False),0).transpose().reshape(-1,1)\n",
    "Zg = np.delete(np.linspace(min(Xtrain),max(Xtrain),num_inducing,endpoint=False),0).transpose().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model build and training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "m = OnOffSVGP(Xtrain, Ytrain\n",
    "              ,kernf=kf,kerng=kg\n",
    "              ,likelihood = OnOffPoissonLikelihood()\n",
    "              ,Zf = Zf,Zg = Zg\n",
    "             )\n",
    "\n",
    "# fix the model noise term\n",
    "#m.likelihood.variance.assign(0.01)\n",
    "from gpflow import set_trainable\n",
    "#set_trainable(m.likelihood.variance, True)\n",
    "\n",
    "minibatch_size = 100\n",
    "\n",
    "N=len(Xtrain)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(Xtrain,),\n",
    "                                                    tf.convert_to_tensor(Ytrain,)),)#.repeat().shuffle(N)\n",
    "\n",
    "train_iter = iter(train_dataset)#batch(minibatch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adam(model, iterations):\n",
    "    \"\"\"\n",
    "    Utility function running the Adam optimizer\n",
    "\n",
    "    :param model: GPflow model\n",
    "    :param interations: number of iterations\n",
    "    \"\"\"\n",
    "    # Create an Adam Optimizer action\n",
    "    logf = []\n",
    "    train_iter = train_dataset#iter(train_dataset.batch(minibatch_size))\n",
    "    training_loss = model.training_loss_closure(compile=True)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=0.005)#gpflow.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    @tf.function\n",
    "    def optimization_step():\n",
    "        optimizer.minimize(training_loss, model.trainable_variables)\n",
    "\n",
    "    for step in range(iterations):\n",
    "        optimization_step()\n",
    "        if step % 10 == 0:\n",
    "            elbo = -training_loss().numpy()\n",
    "            logf.append(elbo)\n",
    "    return logf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=23862.09>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.build_prior_KL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = ci_niter(200000)\n",
    "\n",
    "logf = run_adam(m, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.optimize(maxiter = num_iterations) #,method= tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "m.compute_log_likelihood()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mode fit visualization **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model plot\n",
    "PlotOnOff1D(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.config import default_jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.eye(m.num_inducing_f, dtype=float_type) * default_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.K(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpf.default_float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.Zf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.likelihood.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.kernf.K(m.Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(m.kernf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "optimizer = tf.optimizers.Adam()\n",
    "optimizer.minimize(\n",
    "    m.training_loss_closure(),\n",
    "    m.trainable_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.training_loss_closure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = gpflow.optimizers.Scipy()\n",
    "optimizer.minimize(\n",
    "    m.training_loss_closure(compile=True),\n",
    "    m.trainable_variables,\n",
    "    options=dict(maxiter=(80000),),tol=1e-16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.Zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.Zg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(m.kerng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.kerng.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.kernf.lengthscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.kerng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gpflow.utilities import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.log_posterior_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(logf)), logf)\n",
    "plt.ylim(-200,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
